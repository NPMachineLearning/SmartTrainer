# -*- coding: utf-8 -*-
"""MoViNet_Test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aDfXPLZcU-t8RsmB3Pidrr9nHwvg1mt4

# This is a test of MoViNet

It is based on here: https://www.kaggle.com/models/google/movinet/tensorFlow2/a2-stream-kinetics-600-classification

# Import libraries
"""

# ! pip install -q mediapy
# ! pip install -q opencv-python-headless

from pathlib import Path
import matplotlib.pyplot as plt
# import mediapy as media
import numpy as np
# import PIL

import tensorflow as tf
import tensorflow_hub as hub
# import tqdm
import time

import matplotlib
matplotlib.use('TkAgg')

"""# Get data

- Get kinetics 600 data
- Use jumping jack for test video
"""

# get kinetics 600 label
labels_path = tf.keras.utils.get_file(fname="labels.txt",
                                      origin="https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt",
                                      cache_dir=".",
                                      cache_subdir=".")
labels_path = Path(labels_path)

lines = labels_path.read_text().splitlines()
KINETICS_600_LABELS = np.array([line.strip() for line in lines])
KINETICS_600_LABELS[:20]

# get sample video
jumpingjack_url = "https://github.com/tensorflow/models/raw/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/jumpingjack.gif"
jumpingjack_path = tf.keras.utils.get_file(fname="jumpingjack.gif",
                                           origin=jumpingjack_url,
                                           cache_dir=".",
                                           cache_subdir=".")

# function to load gif
def load_gif(file_path, image_size=(224,224)):
  raw = tf.io.read_file(file_path)
  video = tf.io.decode_gif(raw)
  video = tf.image.resize(video, image_size)
  video = tf.cast(video, tf.float32) / 255.
  return video

# load gif
jumpingjack = load_gif(jumpingjack_path)
print(f"jumping jack shape: {jumpingjack.shape}")

"""# Base model"""

# # load model
# # https://www.kaggle.com/models/google/movinet/frameworks/tensorFlow2/variations/a2-base-kinetics-600-classification/versions/3?tfhub-redirect=true
# hub_url = "https://www.kaggle.com/models/google/movinet/TensorFlow2/a2-base-kinetics-600-classification/3"

# encoder = hub.KerasLayer(hub_url, trainable=True)
# inputs = tf.keras.layers.Input(shape=[None, None, None, 3],
#                                dtype=tf.float32,
#                                name="image")
# outputs = encoder(dict(image=inputs))
# model = tf.keras.Model(inputs, outputs, name="movinet")

# # add batch to video [batch, frames, height, width, color_channel]
# input_video = jumpingjack[tf.newaxis, ...]
# input_video.shape

# # output is in logits
# pred_logit = model(input_video)
# pred_logit.shape

# # convert logit to probability
# pred_prob = tf.nn.softmax(pred_logit, axis=-1)

# # get label and probability
# pred_index = tf.argmax(pred_prob, axis=-1).numpy()[0]
# prob = tf.reduce_max(pred_prob, axis=-1).numpy()[0]
# KINETICS_600_LABELS[pred_index], prob

"""# Streaming model"""

# load model
hub_url = "https://www.kaggle.com/models/google/movinet/TensorFlow2/a2-stream-kinetics-600-classification/2"

encoder = hub.KerasLayer(hub_url, trainable=True)

# image input
# a place holder
# later to be used for creating tensorflow input
image_input = tf.keras.layers.Input(shape=[None, None, None, 3],
                                    dtype=tf.float32,
                                    name="image")

# see what a state look like
init_states_fn = encoder.resolved_object.signatures["init_states"]
next(iter(init_states_fn(tf.constant([0,0,0,0,3])).items()))

# define state
# replace 0 in state shape with None
# result is dict of {state_name:tuple}
# where tuple is (state_shape, state_type)
init_states_fn = encoder.resolved_object.signatures["init_states"]
state_shape = {
    name: ([s if s>0 else None for s in state.shape], state.dtype)
    for name, state in init_states_fn(tf.constant([0,0,0,0,3])).items()
}

# see what is changed
for name in list(state_shape.keys())[:10]:
  print(name, state_shape[name])

# define state inputs
# later to be used for creating model
states_input = {
    name: tf.keras.Input(shape[1:], dtype=dtype, name=name)
    for name, (shape, dtype) in state_shape.items()
}

# see what is changed
for name in list(states_input.keys())[:10]:
  print(name, states_input[name])

# create model
inputs = {**states_input, "image": image_input}
outputs = encoder(inputs)
model = tf.keras.Model(inputs, outputs, name="movinet")

model.summary()

# add batch to video [batch, frames, height, width, color_channel]
input_video = jumpingjack[tf.newaxis, ...]
print(f"input video shape: {input_video.shape}")

# split video into frames
frames = tf.split(input_video, input_video.shape[1], axis=1)
print(f"frames: {len(frames)}")

# see shape of a frame
frame = next(iter(frames))
print(f"frame shape: {frame.shape}")

# initialize state
init_states = model.layers[-1].resolved_object.signatures["init_states"](tf.shape(input_video))

# name, state = next(iter(init_states.items()))
# print(name, state)

# make prediction
# initialize state
states = init_states
# warm up model
_ = model({**states, "image":frame})
predictions = []
times = []
for i, frame in enumerate(frames):
  print(frame.shape)
  start = time.time()
  output, states = model({**states, "image":frame})
  end = time.time()
  times.append(end-start)
  print(f"Frame:{i+1} cost:{end-start:.4f} seconds")
  predictions.append(output)

print(f"Average prediction time per frame: {np.mean(times):.4f} seconds")

final_predicitons = tf.argmax(predictions[-1], axis=-1)
final_predicitons

print(KINETICS_600_LABELS[final_predicitons.numpy()[0]])

# # visualize frame by frame
# import math
# ncols = 2
# nrows = math.ceil(len(frames)/ncols)

# plt.figure(figsize=(12, 12))
# for i, (pred_logit, frame) in enumerate(zip(predictions, frames)):
#   pred_probs = tf.nn.softmax(pred_logit)
#   pred_index = tf.argmax(pred_probs, axis=-1).numpy()[0]
#   prob = tf.reduce_max(pred_probs, axis=-1).numpy()[0]
#   pred_label = KINETICS_600_LABELS[pred_index]
#   # print(KINETICS_600_LABELS[pred_index], f"{prob*100:.2f}%")
#   frame = tf.squeeze(frame, axis=0).numpy()[0]
#   plt.subplot(nrows, ncols, i+1)
#   plt.imshow(frame)
#   plt.axis("off")
#   plt.title(f"Frame:{i+1} | {pred_label} | {prob*100:.2f}%")
# plt.show()

import shutil
import os

if os.path.exists("models"):
  shutil.rmtree("models")
  
# save model
tf.saved_model.save(model, 
                    "models/movinet", 
                    signatures={"init_states": model.layers[-1].resolved_object.signatures["init_states"]})

# zip model
import pathlib
import zipfile

if os.path.exists("models.zip"):
  os.remove("models.zip")

with zipfile.ZipFile("models.zip", "w") as zip_ref:
  p = pathlib.Path("models/movinet").glob("**/*")
  for i in p:
    zip_ref.write(i)